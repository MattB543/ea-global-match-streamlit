#1. Jacob Arbeid — Founder, AI Safety Org

    Why: He’s founding an org to automate AI safety tooling (starting with evals) and wants a technical cofounder; you can add immediate value by scoping an MVP, designing an agentic evals workflow, and pressure-testing what’s actually shippable in 3–6 months. Your founder/product background is directly useful for turning “cool idea” into a funded, operating org.
    Topics to discuss: MVP spec for automated eval pipelines (data ingestion → run harness → reporting); architecture choices (agent frameworks, sandboxing, reproducibility); how to package as “AI Uplift for eval teams” vs standalone org.

#2. Tzu Chan — Chief of Staff, Atlas Computing

    Why: Atlas is explicitly a team-formation engine for unowned AI risk problems; you can help by translating your “AI Uplift” into concrete project proposals Atlas could seed, plus offering productization instincts for internal tools that make their incubation process faster. They also sit at a nexus of funders/leaders, so you can materially help them evaluate what’s buildable and high-leverage.
    Topics to discuss: 2–3 “unowned” AI safety tooling opportunities you could prototype quickly; a repeatable playbook for shipping prototypes for new Atlas-spawned teams; how to scope milestones and de-risk with small pilots.

#3. Marius Hobbhahn — CEO, Apollo Research

    Why: Apollo focuses on scheming/evals/monitoring—areas where operationalizing research into tooling is crucial; you can help by offering product engineering capacity and strong “research-to-software” translation to accelerate internal workflows. If they’re expanding to the Bay in 2026, you can also help them think through what a scalable internal tooling stack should look like.
    Topics to discuss: Internal eval/monitoring tooling roadmap (dashboards, data pipelines, triage UX); automations for red-teaming and experiment management; where a product-minded engineer can multiply researcher output.

#4. Caleb Parikh — Director, EA Funds

    Why: As a grantmaker/hiring manager in AIS, he benefits from meeting builders who can execute quickly; you can offer a crisp picture of “AI Uplift” as a scalable capability for orgs he supports (and a way to reduce operational bottlenecks). You can also help him by packaging what “good tooling” looks like so funding decisions can be more concrete.
    Topics to discuss: Common tooling gaps you’ve seen across EA orgs (knowledge management, eval harnesses, workflow automation); a funding-ready plan for an “AI Uplift” pilot program across multiple grantees; what outcomes/metrics would prove value.

#5. Elizabeth Garrett — (Future of Life Foundation) Builder/Recruiter for Moonshots, Future of Life Foundation

    Why: She’s looking for people to found orgs/build prototypes and wants project ideas that keep AI under human control; you can directly help by proposing concrete, prototype-able tools/services and offering your founder execution skill to move from concept → demo. Your “AI Uplift” lens is useful for quickly validating demand with multiple EA orgs.
    Topics to discuss: 2–3 moonshot-ish product directions you could prototype in weeks; how to validate/iterate with early EA org customers; what team/funding shape makes sense (nonprofit vs startup vs hybrid).

#6. Michael Chen — Member of Policy Staff, METR

    Why: METR often needs strong engineering around evals, processes, and tooling; you can help by offering practical software/product suggestions that reduce friction in policy+research workflows and by connecting “what researchers need” to deployable systems. You can also help by pitching an “AI Uplift” engagement tailored to frontier policy/evals operations.
    Topics to discuss: Tooling to support frontier safety policy advisory (evidence tracking, audit trails, eval result synthesis); lightweight internal products for faster iteration on benchmarks; where METR is bottlenecked on engineering vs research ops.

#7. Isaac Dunn — Program Manager, Constellation

    Why: Constellation hosts and hires; you can help by sharing what kinds of tooling/services are most needed across the residents they support, and by offering a concrete plan to build shared infrastructure that many teams reuse. Your founder/product instincts can help them avoid overbuilding and instead ship the minimum useful platform.
    Topics to discuss: “Shared tooling” opportunities Constellation could provide to many teams (research repo templates, eval harness infra, knowledge bases); how to run a pilot across 3–5 resident teams; what success metrics look like for field-building infrastructure.

#8. Henry Sleight — Research Programs Lead, Constellation

    Why: He’s hiring for research program management and runs pipelines (Astra, etc.); you can help by proposing AI-assisted program ops automations that save staff time and improve candidate evaluation and follow-through. This is a clean fit for “AI Uplift” because programs have repeatable workflows ripe for automation.
    Topics to discuss: Automating application review/support while preserving fairness; AI tools for mentor–fellow matching and progress tracking; lightweight internal tools that reduce coordination overhead across cohorts.

#9. Adeline Sinclair — Research Recruiting, Anthropic

    Why: As a recruiter for interpretability/RSP/education, she can benefit from your ability to help strong candidates present clearly and to identify what proof-of-work best signals capability; you can also feed her pipeline by connecting her to engineers/researchers you meet. You add value by translating “what Anthropic needs” into concrete next steps for builders and program participants.
    Topics to discuss: What portfolios/projects most strongly signal for interpretability/RSP-adjacent roles; how to coach candidates on framing (without hype); which roles could benefit from a product-minded “tooling” profile.

#10. James Bowler — Technical Strategy & Execution Lead, AE Studio

    Why: AE Studio monetizes/funds alignment research and is hiring; you can help by identifying productizable research outputs and shaping them into tools clients/users actually adopt. Your startup/product background is especially useful in converting research prototypes into robust offerings.
    Topics to discuss: Which alignment research threads could become deployable tools; packaging/positioning for safety tooling buyers (labs, auditors, regulated orgs); how to structure a “research → prototype → paid pilot” loop.

#11. Lindley Lentati — Director & Co-Founder, Cambridge Inference

    Why: They’re building an AI control/monitoring platform and want feedback from control researchers; you can add value by bringing strong product engineering instincts—how to make control research usable in production, with UX, integration, and reliability. You can also share “AI Uplift” patterns for rolling out monitoring tools inside organizations.
    Topics to discuss: Product requirements for human oversight dashboards; integration patterns with existing enterprise stacks; roadmap tradeoffs: dataset generation, evals, agentic control protocols.

#12. Walter Laurito — Co-director & Researcher, Cadenza Labs

    Why: He’s looking for collaborators to create “model organisms” for deception detection competitions; you can help by structuring the project like a product (clear user journey, reproducible infra, scoring/leaderboards) and offering engineering execution to ship a competition platform. This is a high-leverage place to turn research ideas into community-scaled artifacts.
    Topics to discuss: Competition design: tasks, scoring, baselines, anti-Goodhart measures; infra plan (containers, eval harness, reporting UI); how to attract participants and partners (labs, programs, funders).

#13. Jacob Kopczynski — Site Reliability Engineer/Senior Software Engineer, (Independent)

    Why: He’s exploring whether he should work on technical AI safety; you can provide unusually practical guidance on “how to contribute as an engineer” and suggest concrete projects where SRE skills matter (reproducibility, eval infra, secure sandboxes). This can directly accelerate his pivot and reduce flailing.
    Topics to discuss: A 3-project portfolio plan (eval harness reliability, dataset/versioning, secure execution); which orgs value SRE profiles in safety; how to market “production safety infra” as a core safety contribution.

#14. Stacey Svetlichnaya — AI Ecosystem Engineer, Self-employed

    Why: She has deep AI engineering experience (W&B, AI Objectives Institute) and wants a small mission-focused team; you can add value by helping her converge on a product direction and packaging her strengths into a shippable “AI safety tooling” offering. You may also find strong collaboration synergy (you: product/founder, her: deep ML tooling).
    Topics to discuss: Picking a single wedge product (monitoring viz, CoT tooling, workflow infra) and defining target users; go-to-market in the AIS ecosystem; how to structure a small team + funding plan.

#15. Suhan Kacholia — Co-Founder/CTO, Analogy Group

    Why: They’re hiring and seeking funding for an AI political research platform; you can provide high-leverage product strategy, technical architecture feedback, and help shape their offering for EA-aligned policy orgs (where you already serve customers). You can also help them clarify what to build next for decision-grade usefulness.
    Topics to discuss: Product roadmap for policy research workflows (briefs → citations → uncertainty); evaluation metrics for “decision usefulness”; packaging pilots with EA policy orgs and grantmakers.

#16. Mariana Oka — Co-founder & Head of Product, Ideosphere

    Why: Ideosphere needs actionable question design and early users; you can help by turning org needs you’ve observed into high-value forecast questions and by advising on onboarding UX that gets forecasters to high-quality output fast. Your “AI Uplift” work gives you a broad view of decision bottlenecks across orgs.
    Topics to discuss: A starter set of “decision-grade” forecasts for AI safety org operations (hiring, funding, research bets); tooling to prevent Goodharting and improve calibration feedback loops; product UX for cohort onboarding and retention.

#17. Tao Burga — AI Policy and Def/Acc, Institute for Progress (IFP)

    Why: He’s actively soliciting “things we should build before advanced AI” and needs evaluators/advisors; you can contribute by pitching concrete buildable projects and by offering to prototype early versions quickly to de-risk proposals. Your founder background helps translate policy desiderata into real tools.
    Topics to discuss: A pitch for an “AI Uplift for resilience/verification” pilot aligned with The Launch Sequence; rapid prototyping plan + milestones; how to evaluate proposals for technical feasibility and adoption risk.

#18. David Krueger — CEO/Assistant Professor, Evitable | Mila / University of Montreal

    Why: He wants help “running things” for outreach and is looking for collaborators/employees; you can add value by proposing scalable, software-enabled outreach workflows (content pipelines, targeting, measurement) and by offering product leadership to operationalize outreach into a repeatable system. You can also help stress-test what to automate vs what must remain human-led.
    Topics to discuss: Tooling for outreach ops (CRM, experiment tracking, distribution automation); measurement strategy for awareness/attitude change; what an MVP of Evitable’s product could be and how to staff it.

#19. Simeon Campos — Co-Founder & CEO, Humanis

    Why: He’s hiring founding scientists for an ambitious verification agenda; you can help by clarifying what supporting engineering/product roles are needed to make researchers effective (pipelines, eval infra, demos for funders). As a founder, you can also pressure-test their execution plan and early milestones.
    Topics to discuss: What the first 90 days of “world-model verification” needs in tooling; how to build credibility fast (benchmarks, demos, papers); hiring plan that pairs research with strong engineering execution.

#20. Max Werner — Engineering Lead/Entrepreneur, conLeos GmbH

    Why: He wants collaborators to start something new in AI safety product space and is open to feedback; you can provide founder-to-founder value by jointly identifying a tractable wedge product and mapping customer discovery in the EA/AIS ecosystem. This is a high-upside peer collaboration where your product skills compound.
    Topics to discuss: Candidate product ideas and a quick validation plan; forming a cofounder agreement and division of responsibilities; how to sell to AIS orgs without becoming a bespoke consulting shop.

#21. Benjamin Hodgkiss — Founder (in formation), AI Verification for Treaty (Independent)

    Why: He’s building an org around verification/tamper-evident hardware and wants a technical cofounder and collaborators; you can help by translating his ToC into a concrete product roadmap and identifying what to prototype first to unlock funding/partners. Your startup/product experience is valuable for turning treaty-oriented ideas into credible execution steps.
    Topics to discuss: MVP for tamper-evident monitoring hardware + software chain-of-custody; stakeholder mapping and “who buys/uses this first”; de-risk plan (manufacturing, deployment, audits).

#22. Quinn Dougherty — Research Engineer, Beneficial AI Foundation / Galois / Forall LLC

    Why: He’s doing formal methods + AI security and may hire research engineers; you can help by making his work legible and adoptable—productizing the position paper, building supporting demos, and shaping a tool strategy that maps to real users. You can also share founder/product lessons for running a small contracting/LLC-based research effort.
    Topics to discuss: Turning formal methods ideas into a demo that convinces skeptics; packaging “secure AI with formal methods” for different audiences (labs vs policymakers); lightweight operational systems for hiring/contracting and shipping.

#23. Sarah Cheng — EA Forum Project Lead, Centre for Effective Altruism

    Why: She’s exploring new web products to help grow EA; you can provide direct product/engineering value by proposing AI-native features that improve discovery, summarization, and collaboration on the Forum (and by sharing what you’ve learned delivering AI tools to EA orgs). This is a place where your “AI Uplift” approach can scale to thousands of users.
    Topics to discuss: AI-assisted reading/synthesis features (summaries, argument maps, topic digests); tooling to help authors draft higher-quality posts; experiments to improve onboarding and retention of new EAs.

#24. Joly Scriven — Operations Lead, ARENA (Alignment Research Engineer Accelerator)

    Why: ARENA is scaling and expanding to the US; you can add value by helping them systematize operations with automation (applications, logistics, curriculum distribution, alumni tracking) and by sharing startup-style scaling tactics. This directly increases their throughput of alignment engineers.
    Topics to discuss: Automations for admissions, scheduling, and learner support; building a remote-friendly “ARENA at scale” platform; metrics and dashboards to track outcomes (placements, skill growth).

#25. James Hindmarch — Programme Lead, ARENA

    Why: He wants feedback from hirers on what skills matter and is exploring collaboration; you can contribute by translating employer needs into curriculum-aligned projects and by proposing tool-based assignments that mimic real AIS engineering work. Your product engineering lens helps design exercises that produce credible work samples.
    Topics to discuss: “Industry-grade” capstone projects (eval harness, monitoring dashboards, reproducibility tooling); how to teach agentic tooling safely; creating a portfolio rubric that hiring managers actually trust.
